version: '3.7'

services:
  spark-master:
    image: bitnami/spark:latest
    hostname: spark-master
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/tmp/spark-events  # Ensuring the Spark job knows where to write logs
    ports:
      - "8080:8080"
    networks:
      - spark-network

  jupyter:
    build: .
    ports:
      - "8888:8888"
    networks:
      - spark-network
    volumes:
      - ./local_lake:/home/jovyan/work
      - ./notebooks:/home/jovyan/
      - .:/opt/spark/work-dir  # This mounts the current directory to /opt/spark/work-dir in the container
      - /tmp/spark/spark-events:/tmp/spark-events  # Ensure logs are written here
      
    depends_on:
      - spark-master
    command: "start-notebook.sh --NotebookApp.token='' --NotebookApp.password=''"

  spark-history-server:
    image: rangareddy1988/spark-history-server:${VERSION:-latest}
    container_name: spark-history-server
    environment:
      - SPARK_HISTORY_FS_LOGDIRECTORY=/tmp/spark-events  # Point to the directory where logs are stored
      - SPARK_HISTORY_UI_PORT=18080
    ports:
      - 18080:18080
      - 4041:4040
    networks:
      - spark-network
    volumes:
      - /tmp/spark/spark-events:/tmp/spark-events  # Shared volume for logs
      - /tmp/spark/spark-history-server-logs:/var/log/spark

networks:
  spark-network:
